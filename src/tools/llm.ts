import { Logger } from 'pino';
import { LLMProviderManager } from '../core/llm-provider.js';
import { LLMTransformInput, LLMTransformOutput, JSONSchema, LLMInputData } from '../types/llm.js';
import { ErrorResponse } from '../types/index.js';
import Ajv from 'ajv';

export class LLMTools {
  private ajv = new (Ajv as any)();

  constructor(
    private llmManager: LLMProviderManager,
    private logger: Logger,
    private config?: { autoPreprocess?: boolean }
  ) {}

  async transform(params: LLMTransformInput): Promise<LLMTransformOutput | ErrorResponse> {
    const startTime = Date.now();
    this.logger.info({ 
      model: params.model, 
      inputKind: params.input.kind,
      dataLength: params.input.data.length,
      hasPreprocessRequest: !!params.preprocessRequest
    }, 'Starting LLM transformation');

    try {
      let processedInput = params.input;
      let preprocessRequest = params.preprocessRequest;

      // Auto-generate preprocessing request if not provided and auto-preprocess is enabled
      if (!preprocessRequest && 
          (this.config?.autoPreprocess !== false) && 
          this.shouldAutoPreprocess(params.input, params.instruction)) {
        preprocessRequest = this.generateAutoPreprocessRequest(params.input, params.instruction);
        this.logger.info({ autoGeneratedPreprocess: preprocessRequest }, 'Auto-generated preprocessing request');
      }

      // Preprocessing step if requested or auto-generated
      if (preprocessRequest) {
        this.logger.info({ isAutoGenerated: !params.preprocessRequest }, 'Running preprocessing step');
        
        const preprocessPrompt = this.buildPreprocessPrompt(params.input, preprocessRequest);
        
        // Use local model for preprocessing (prefer ollama or jan)
        const preprocessModel = this.getLocalModel(params.model);
        
        const preprocessResponse = await this.llmManager.generate({
          systemPrompt: 'You are a data preprocessor. Clean and prepare the data according to the request. Return only the processed data without additional commentary.',
          userPrompt: preprocessPrompt,
          maxTokens: params.maxOutputTokens,
          temperature: 0.1, // Lower temperature for preprocessing
          model: preprocessModel
        });

        // Update input with preprocessed data
        processedInput = {
          kind: params.input.kind,
          data: preprocessResponse.content.trim()
        };

        this.logger.info({ 
          originalLength: params.input.data.length,
          processedLength: processedInput.data.length,
          preprocessRequest: preprocessRequest
        }, 'Preprocessing completed');
      }

      // Prepare the user prompt with processed input
      const userPrompt = this.buildUserPrompt({ ...params, input: processedInput });

      // Call LLM for main processing
      const response = await this.llmManager.generate({
        systemPrompt: params.systemPrompt,
        userPrompt,
        maxTokens: params.maxOutputTokens,
        temperature: params.temperature,
        model: params.model
      });

      // Parse and validate result
      const result = await this.parseAndValidateResult(response.content, params.schema);

      const duration = Date.now() - startTime;
      this.logger.info({ 
        model: params.model, 
        tokensUsed: response.tokensUsed,
        duration 
      }, 'LLM transformation completed');

      return {
        status: 'ok',
        result,
        raw: response.content,
        model: params.model,
        tokensUsed: response.tokensUsed
      };

    } catch (error) {
      const duration = Date.now() - startTime;
      this.logger.error({ 
        model: params.model,
        error: error instanceof Error ? error.message : String(error),
        duration 
      }, 'LLM transformation failed');

      return {
        status: 'error',
        code: 'llm_failed',
        message: error instanceof Error ? error.message : 'Unknown error during LLM transformation',
        details: { 
          model: params.model,
          inputKind: params.input.kind 
        }
      };
    }
  }

  private buildUserPrompt(params: LLMTransformInput): string {
    let prompt = `Task: ${params.instruction}\n\n`;

    // Add input data with context
    switch (params.input.kind) {
      case 'text':
        prompt += `Text content:\n${params.input.data}`;
        break;
      case 'html':
        prompt += `HTML content:\n${params.input.data}`;
        break;
      case 'json':
        prompt += `JSON data:\n${params.input.data}`;
        break;
    }

    // Add schema requirements if provided
    if (params.schema) {
      prompt += `\n\nRequired output format (JSON Schema):\n${JSON.stringify(params.schema, null, 2)}`;
      prompt += `\n\nPlease return ONLY valid JSON that conforms to the above schema.`;
    } else {
      prompt += `\n\nPlease return the result as valid JSON.`;
    }

    return prompt;
  }

  private async parseAndValidateResult(content: string, schema?: JSONSchema): Promise<any> {
    // Try to extract JSON from the response
    let jsonStr = content.trim();
    
    // If content is wrapped in markdown code blocks, extract the JSON
    const jsonMatch = jsonStr.match(/```(?:json)?\s*([\s\S]*?)\s*```/);
    if (jsonMatch) {
      jsonStr = jsonMatch[1].trim();
    }

    // Parse JSON
    let result: any;
    try {
      result = JSON.parse(jsonStr);
    } catch (parseError) {
      // Try to find JSON-like content in the response
      const potentialJson = this.extractPotentialJson(jsonStr);
      if (potentialJson) {
        try {
          result = JSON.parse(potentialJson);
        } catch (secondParseError) {
          throw new Error(`Invalid JSON response: ${parseError instanceof Error ? parseError.message : 'Parse error'}`);
        }
      } else {
        throw new Error(`No valid JSON found in response: ${parseError instanceof Error ? parseError.message : 'Parse error'}`);
      }
    }

    // Validate against schema if provided
    if (schema) {
      const validate = this.ajv.compile(schema);
      const valid = validate(result);
      
      if (!valid) {
        const errors = validate.errors?.map((err: any) => `${err.instancePath}: ${err.message}`).join(', ') || 'Unknown validation error';
        throw new Error(`Schema validation failed: ${errors}`);
      }
    }

    return result;
  }

  private extractPotentialJson(text: string): string | null {
    // Look for JSON objects or arrays in the text
    const patterns = [
      /\{[\s\S]*\}/,  // Object
      /\[[\s\S]*\]/   // Array
    ];

    for (const pattern of patterns) {
      const match = text.match(pattern);
      if (match) {
        return match[0];
      }
    }

    return null;
  }

  private buildPreprocessPrompt(input: LLMInputData, preprocessRequest: string): string {
    let prompt = `Preprocessing request: ${preprocessRequest}\n\n`;

    switch (input.kind) {
      case 'text':
        prompt += `Text content to preprocess:\n${input.data}`;
        break;
      case 'html':
        prompt += `HTML content to preprocess:\n${input.data}`;
        break;
      case 'json':
        prompt += `JSON data to preprocess:\n${input.data}`;
        break;
    }

    prompt += `\n\nPlease preprocess the above ${input.kind} according to the request and return only the processed data.`;
    
    return prompt;
  }

  private getLocalModel(currentModel: string): string {
    // If already using a local model, keep it
    if (currentModel.startsWith('ollama:') || currentModel.startsWith('jan:')) {
      return currentModel;
    }

    // Prefer Ollama for preprocessing (usually faster and free)
    // Try to use a lightweight model for preprocessing
    const commonOllamaModels = [
      'ollama:llama3.1',
      'ollama:llama3.1:8b',
      'ollama:llama2',
      'ollama:mistral',
      'ollama:qwen2.5'
    ];

    // Return the first available model, or fallback to jan or the original model
    for (const model of commonOllamaModels) {
      try {
        // We could check if model is available, but for now just return the first
        return model;
      } catch (error) {
        continue;
      }
    }

    // Fallback to JAN or original model
    if (process.env.JAN_API_KEY) {
      return 'jan:llama-3.1-8b';
    }

    return currentModel;
  }

  private shouldAutoPreprocess(input: LLMInputData, instruction: string): boolean {
    // Auto-preprocess for large HTML content
    if (input.kind === 'html' && input.data.length > 5000) {
      return true;
    }

    // Auto-preprocess for messy text content
    if (input.kind === 'text' && input.data.length > 3000) {
      return true;
    }

    // Auto-preprocess for complex JSON data
    if (input.kind === 'json') {
      try {
        const parsed = JSON.parse(input.data);
        // If it's a large object or array, preprocess
        if (Array.isArray(parsed) && parsed.length > 10) return true;
        if (typeof parsed === 'object' && Object.keys(parsed).length > 20) return true;
      } catch {
        // If JSON is malformed, definitely preprocess
        return true;
      }
    }

    // Auto-preprocess if instruction suggests cleaning or extraction
    const cleaningKeywords = ['clean', 'extract', 'parse', 'standardize', 'normalize', 'filter', 'remove'];
    const instructionLower = instruction.toLowerCase();
    if (cleaningKeywords.some(keyword => instructionLower.includes(keyword))) {
      return true;
    }

    return false;
  }

  private generateAutoPreprocessRequest(input: LLMInputData, instruction: string): string {
    const instructionLower = instruction.toLowerCase();
    
    switch (input.kind) {
      case 'html':
        let htmlRequest = 'Remove unnecessary HTML elements: navigation, footer, advertisements, scripts, and styles. ';
        
        if (instructionLower.includes('table')) {
          htmlRequest += 'Focus on preserving table structures and data. ';
        } else if (instructionLower.includes('product') || instructionLower.includes('item')) {
          htmlRequest += 'Focus on product/item information content. ';
        } else if (instructionLower.includes('article') || instructionLower.includes('content')) {
          htmlRequest += 'Focus on main article content. ';
        }
        
        htmlRequest += 'Keep only the relevant content for the main task.';
        return htmlRequest;

      case 'text':
        let textRequest = 'Clean and normalize the text: fix typos, normalize whitespace, remove duplicate sentences. ';
        
        if (instructionLower.includes('summary') || instructionLower.includes('extract')) {
          textRequest += 'Organize content logically and remove irrelevant details. ';
        } else if (instructionLower.includes('data') || instructionLower.includes('parse')) {
          textRequest += 'Extract and organize structured information. ';
        }
        
        textRequest += 'Prepare clean text for further processing.';
        return textRequest;

      case 'json':
        let jsonRequest = 'Clean JSON data: remove null/empty values, standardize field names. ';
        
        if (instructionLower.includes('table') || instructionLower.includes('rows')) {
          jsonRequest += 'Remove empty rows, merge duplicate entries. ';
        }
        
        if (instructionLower.includes('date')) {
          jsonRequest += 'Standardize date formats to YYYY-MM-DD. ';
        }
        
        if (instructionLower.includes('currency') || instructionLower.includes('price')) {
          jsonRequest += 'Normalize currency values. ';
        }
        
        jsonRequest += 'Ensure consistent data types and structure.';
        return jsonRequest;

      default:
        return 'Clean and prepare the data for better processing by removing noise and standardizing format.';
    }
  }
}
